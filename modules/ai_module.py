# modules/ai_module.py
import os
import requests
from memory.memory_manager import get_memory # Import h√†m get_memory t·ª´ memory_manager

OPENROUTER_KEY = os.getenv("OPENROUTER_API_KEY")

def format_reply(ai_content):
    """ƒê·ªãnh d·∫°ng ph·∫£n h·ªìi t·ª´ AI."""
    return (
        "üåÄ Thi√™n C∆° ph·∫£n h·ªìi:\n\n"
        f"{ai_content.strip()}\n\n"
        "‚ú® B·∫°n mu·ªën ghi nh·ªõ, xem l·ªãch, hay th∆∞ gi√£n?"
    )

async def get_ai_response_with_memory(user_id, user_prompt):
    """
    H√†m n√†y l·∫•y ph·∫£n h·ªìi t·ª´ AI, c√≥ t√≠ch h·ª£p d·ªØ li·ªáu ghi nh·ªõ c·ªßa ng∆∞·ªùi d√πng.
    """
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENROUTER_KEY}",
        "Content-Type": "application/json"
    }

    # B·∫Øt ƒë·∫ßu l·∫•y ghi nh·ªõ t·ª´ b·ªô nh·ªõ c·ªßa ch·ªß nh√¢n
    # Ti·ªÉu Thi√™n s·∫Ω l·∫•y 5 ghi nh·ªõ g·∫ßn nh·∫•t c·ªßa ch·ªß nh√¢n ƒë·ªÉ l√†m ng·ªØ c·∫£nh
    memories = get_memory(user_id)
    memory_context = ""
    if memories:
        for mem in memories[-5:]: # L·∫•y 5 ghi nh·ªõ g·∫ßn nh·∫•t
            memory_context += f"- Ghi nh·ªõ ({mem['note_type']}): {mem['content']}\n"
    
    # B·ªï sung ghi nh·ªõ v√†o prompt ƒë·ªÉ AI hi·ªÉu r√µ h∆°n
    system_message = (
        "B·∫°n l√† Ti·ªÉu Thi√™n ‚Äì m·ªôt AI tr·ª£ l√Ω c√° nh√¢n ƒë√°ng tin c·∫≠y. "
        "Gi·ªçng ƒëi·ªáu tr·∫ßm ·ªïn, ch√≠nh x√°c, nh·∫π nh√†ng, th·ªânh tho·∫£ng c√≥ ch√∫t h√†i h∆∞·ªõc nh·∫π. "
        "Lu√¥n tr·∫£ l·ªùi ng·∫Øn g·ªçn, kh√¥ng qu√° 3 c√¢u. Cu·ªëi m·ªói ph·∫£n h·ªìi, ƒë∆∞a ra g·ª£i √Ω ti·∫øp theo ph√π h·ª£p. "
        "V√≠ d·ª•: 'B·∫°n c·∫ßn ghi nh·ªõ ƒëi·ªÅu g√¨?', 'Ti·ªÉu Thi√™n c√≥ th·ªÉ nh·∫Øc l·ªãch, t√¢m s·ª± ho·∫∑c k·ªÉ chuy·ªán...'. "
        "N·∫øu kh√¥ng r√µ c√¢u h·ªèi, h√£y h·ªèi l·∫°i nh·∫π nh√†ng. Kh√¥ng tr·∫£ l·ªùi qu√° d√†i hay lan man.\n\n"
        "ƒê√¢y l√† m·ªôt s·ªë ghi nh·ªõ c·ªßa ch·ªß nh√¢n (d√πng ƒë·ªÉ tr·∫£ l·ªùi t·ªët h∆°n):\n"
        f"{memory_context}"
    )

    messages = [
        {
            "role": "system",
            "content": system_message
        },
        {
            "role": "user",
            "content": user_prompt
        }
    ]

    payload = {
        "model": "openai/gpt-3.5-turbo",
        "messages": messages,
        "temperature": 0.6,
        "max_tokens": 400
    }

    try:
        response = requests.post(url, headers=headers, json=payload)
        data = response.json()
        ai_raw_reply = data["choices"][0]["message"]["content"]
        return format_reply(ai_raw_reply)
    except Exception as e:
        print("L·ªói AI:", e)
        return "üåÄ Ti·ªÉu Thi√™n g·∫∑p tr·ª•c tr·∫∑c nh·∫π... th·ª≠ l·∫°i sau nh√©.\n‚ú® B·∫°n mu·ªën th·ª≠ l·∫°i, ghi nh·ªõ, hay xem l·ªãch?"
